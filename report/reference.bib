@article{compiler-for-hpc,
author = {Bacon, David F. and Graham, Susan L. and Sharp, Oliver J.},
title = {Compiler transformations for high-performance computing},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/197405.197406},
doi = {10.1145/197405.197406},
abstract = {In the last three decades a large number of compiler transformations for optimizing programs have been implemented. Most optimizations for uniprocessors reduce the number of instructions executed by the program using transformations based on the analysis of scalar quantities and data-flow techniques. In contrast, optimizations for high-performance superscalar, vector, and parallel processors maximize parallelism and memory locality with transformations that rely on tracking the properties of arrays using loop dependence analysis.This survey is a comprehensive overview of the important high-level program restructuring techniques for imperative languages, such as C and Fortran. Transformations for both sequential and various types of parallel architectures are covered in depth. We describe the purpose of each transformation, explain how to determine if it is legal, and give an example of its application.Programmers wishing to enhance the performance of their code can use this survey to improve their understanding of the optimizations that compilers can perform, or as a reference for techniques to be applied manually. Students can obtain an overview of optimizing compiler technology. Compiler writers can use this survey as a reference for most of the important optimizations developed to date, and as bibliographic reference for the details of each optimization. Readers are expected to be familiar with modern computer architecture and basic program compilation techniques.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {345â€“420},
numpages = {76},
keywords = {compilation, dependence analysis, locality, multiprocessors, optimization, parallelism, superscalar processors, vectorization}
}
